import os
import time
from typing import TYPE_CHECKING, Any, Dict, List

from langchain_core.messages import AIMessage, HumanMessage

# æ–°å¢å¯¼å…¥
from langchain_openai import AzureChatOpenAI

from config import config
from reasoning_strategies import (
    ComplexityAnalysisResult,
    ProblemComplexity,
    ReasoningContext,
    ReasoningStrategy,
    strategy_manager,
)
from tools import get_react_tools, resolve_params, resolve_tool_name
from tools.mcp_adapter import mcp_adapter

# åŠ è½½ .env æ–‡ä»¶
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    # å¦‚æœæ²¡æœ‰å®‰è£… python-dotenvï¼Œç»§ç»­æ‰§è¡Œ
    pass

if TYPE_CHECKING:
    from state import ReActState

# Azure OpenAI é…ç½®
AZURE_OPENAI_DEPLOYMENT = os.getenv(
    "AZURE_OPENAI_CHAT_DEPLOYMENT_NAME", "gpt-4o-mini")
AZURE_OPENAI_API_VERSION = os.getenv(
    "AZURE_OPENAI_API_VERSION", "2024-12-01-preview")
AZURE_OPENAI_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT")
AZURE_OPENAI_API_KEY = os.getenv("AZURE_OPENAI_API_KEY")

llm = None
if AZURE_OPENAI_ENDPOINT and AZURE_OPENAI_API_KEY:
    llm = AzureChatOpenAI(
        azure_endpoint=AZURE_OPENAI_ENDPOINT,
        azure_deployment=AZURE_OPENAI_DEPLOYMENT,
        api_version=AZURE_OPENAI_API_VERSION,
        api_key=AZURE_OPENAI_API_KEY,  # type: ignore
        temperature=0.2,
    )


async def evaluate_result_quality(
    original_problem: str,
    final_answer: str,
    reasoning_chain: List[Dict[str, str]],
    file_check_result: Dict[str, Any],
    llm
) -> str:
    """è¯„ä¼°ç»“æœè´¨é‡å¹¶æä¾›ä¼˜åŒ–å»ºè®®"""

    if not llm:
        return "ğŸ“Š ç»“æœè´¨é‡è¯„ä¼°: æœªé…ç½®LLMï¼Œæ— æ³•è¿›è¡Œè¯„ä¼°"

    try:
        # æ„å»ºè¯„ä¼°ä¸Šä¸‹æ–‡
        context = f"""
åŸå§‹é—®é¢˜: {original_problem}

æœ€ç»ˆç­”æ¡ˆ: {final_answer}

æ¨ç†è¿‡ç¨‹æ¦‚è¦:
"""

        for i, step in enumerate(reasoning_chain, 1):
            context += f"æ­¥éª¤{i}: {step.get('action', '')}\n"

        context += f"""
æ–‡ä»¶ç”Ÿæˆæƒ…å†µ:
- æœ‰æ–‡ä»¶è¦æ±‚: {file_check_result.get('has_file_requirement', False)}
- ç”Ÿæˆçš„æ–‡ä»¶: {file_check_result.get('existing_files', [])}
- ç¼ºå¤±çš„æ–‡ä»¶: {file_check_result.get('missing_files', [])}
"""

        prompt = f"""
è¯·å¯¹ä»¥ä¸‹é—®é¢˜è§£å†³è¿‡ç¨‹è¿›è¡Œè´¨é‡è¯„ä¼°å’Œä¼˜åŒ–å»ºè®®ï¼š

{context}

è¯·ä»ä»¥ä¸‹ç»´åº¦è¿›è¡Œè¯„ä¼°ï¼š

**ğŸ” å®Œæ•´æ€§è¯„ä¼° (0-10åˆ†)**
- æ˜¯å¦å®Œå…¨å›ç­”äº†ç”¨æˆ·çš„é—®é¢˜ï¼Ÿ
- æ˜¯å¦é—æ¼äº†ä»»ä½•é‡è¦ä¿¡æ¯ï¼Ÿ
- æ˜¯å¦æ»¡è¶³äº†æ‰€æœ‰æ˜ç¡®æå‡ºçš„è¦æ±‚ï¼Ÿ

**ğŸ¯ å‡†ç¡®æ€§è¯„ä¼° (0-10åˆ†)**
- ä¿¡æ¯æ˜¯å¦å‡†ç¡®å¯ä¿¡ï¼Ÿ
- è®¡ç®—å’Œæ•°æ®æ˜¯å¦æ­£ç¡®ï¼Ÿ
- æ˜¯å¦æœ‰é€»è¾‘é”™è¯¯ï¼Ÿ

**ğŸ“‹ å®ç”¨æ€§è¯„ä¼° (0-10åˆ†)**
- ç»“æœæ˜¯å¦å¯¹ç”¨æˆ·æœ‰å®é™…å¸®åŠ©ï¼Ÿ
- æ˜¯å¦æä¾›äº†å¯è¡Œçš„æ–¹æ¡ˆï¼Ÿ
- æ ¼å¼æ˜¯å¦ç¬¦åˆç”¨æˆ·æœŸæœ›ï¼Ÿ

**ğŸ¨ å‘ˆç°è´¨é‡è¯„ä¼° (0-10åˆ†)**
- ç­”æ¡ˆæ˜¯å¦æ¸…æ™°æ˜“æ‡‚ï¼Ÿ
- ç»“æ„æ˜¯å¦åˆç†ï¼Ÿ
- æ˜¯å¦æœ‰è¶³å¤Ÿçš„ç»†èŠ‚ï¼Ÿ

**ğŸ’¡ ä¼˜åŒ–å»ºè®®**
- æœ‰å“ªäº›å¯ä»¥æ”¹è¿›çš„åœ°æ–¹ï¼Ÿ
- æ˜¯å¦éœ€è¦è¡¥å……é¢å¤–ä¿¡æ¯ï¼Ÿ
- æœ‰ä»€ä¹ˆåç»­è¡ŒåŠ¨å»ºè®®ï¼Ÿ

è¯·ç”¨ä»¥ä¸‹æ ¼å¼è¿”å›è¯„ä¼°ç»“æœï¼š

ğŸ“Š **ç»“æœè´¨é‡è¯„ä¼°æŠ¥å‘Š**

ğŸ” **å®Œæ•´æ€§**: X/10 - è¯„ä¼°è¯´æ˜
ğŸ¯ **å‡†ç¡®æ€§**: X/10 - è¯„ä¼°è¯´æ˜  
ğŸ“‹ **å®ç”¨æ€§**: X/10 - è¯„ä¼°è¯´æ˜
ğŸ¨ **å‘ˆç°è´¨é‡**: X/10 - è¯„ä¼°è¯´æ˜

â­ **ç»¼åˆè¯„åˆ†**: X/10

ğŸ’¡ **ä¼˜åŒ–å»ºè®®**:
1. å»ºè®®1
2. å»ºè®®2
3. å»ºè®®3

ğŸš€ **åç»­è¡ŒåŠ¨**:
- è¡ŒåŠ¨1
- è¡ŒåŠ¨2
"""

        print("ğŸ¤– æ­£åœ¨è¿›è¡Œç»“æœè´¨é‡è¯„ä¼°...")
        response = await llm.ainvoke([HumanMessage(content=prompt)])

        assessment = str(response.content).strip()
        print("ğŸ“Š è´¨é‡è¯„ä¼°å®Œæˆ")

        return assessment

    except Exception as e:
        print(f"âŒ ç»“æœè´¨é‡è¯„ä¼°å¤±è´¥: {e}")
        return f"ğŸ“Š ç»“æœè´¨é‡è¯„ä¼°: è¯„ä¼°è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ - {str(e)}"


async def react_reasoning_agent(state: 'ReActState') -> 'ReActState':
    """ReActæ¨ç†æ™ºèƒ½ä½“ - è´Ÿè´£æ€è€ƒå’Œå†³ç­–"""

    current_iter = state.get("current_iteration", 0)
    max_iter = state.get("max_iterations", config.DEFAULT_MAX_ITERATIONS)
    user_message = state.get("current_problem", "")

    print(f"\nğŸ§  [æ­¥éª¤{current_iter + 1}] å¼€å§‹æ¨ç†...")

    # ğŸ†• æ™ºèƒ½æ¨ç†ç­–ç•¥é€‰æ‹©
    if current_iter == 0:  # ç¬¬ä¸€è½®æ¨ç†æ—¶åˆ†æé—®é¢˜å¹¶é€‰æ‹©ç­–ç•¥
        # è·å–å¯ç”¨å·¥å…·ä¿¡æ¯
        available_tools = get_react_tools()
        available_tool_names = [tool.name for tool in available_tools]

        complexity_result = strategy_manager.analyze_problem_complexity(
            user_message, llm=llm, available_tools=available_tool_names)
        complexity = complexity_result.complexity
        recommended_tools = complexity_result.recommended_tools
        strategy = strategy_manager.select_strategy(complexity)

        print(f"ğŸ“Š å¤æ‚åº¦: {complexity.value} | ç­–ç•¥: {strategy.value}")
        print(f"ğŸ¯ æ¨èå·¥å…·: {', '.join(recommended_tools[:3])}")

        # æ ¹æ®çŠ¶æ€ä¸­çš„é…ç½®å†³å®šæ˜¯å¦è‡ªåŠ¨è°ƒæ•´æœ€å¤§è¿­ä»£æ¬¡æ•°
        auto_adjust = state.get("auto_adjust_iterations",
                                config.AUTO_ADJUST_ITERATIONS)
        if auto_adjust:
            # ğŸ†• æ ¹æ®è¿­ä»£æ§åˆ¶æ¨¡å¼è°ƒæ•´è¿­ä»£æ¬¡æ•°
            control_mode = getattr(
                config, 'ITERATION_CONTROL_MODE', 'intelligent')

            if control_mode == "strict":
                # ä¸¥æ ¼æ¨¡å¼ï¼šæŒ‰ç­–ç•¥é™åˆ¶ï¼Œä¸å…è®¸è¶…å‡º
                strategy_config = strategy_manager.strategy_configs[strategy]
                max_iter = strategy_config["max_iterations"]

            elif control_mode == "intelligent":
                # æ™ºèƒ½æ¨¡å¼ï¼šåŸºäºä»»åŠ¡å¤æ‚åº¦å’Œéœ€æ±‚æ™ºèƒ½è°ƒæ•´
                intelligent_config = getattr(
                    config, 'INTELLIGENT_ADJUSTMENT_CONFIG', {})
                base_iterations = intelligent_config.get("base_iterations", 6)
                max_safe_iterations = intelligent_config.get(
                    "max_safe_iterations", 20)

                # åŸºç¡€è¿­ä»£æ¬¡æ•°
                max_iter = base_iterations

                # ğŸ†• æ ¹æ®ä»»åŠ¡å¤æ‚åº¦è°ƒæ•´
                complexity_multiplier = {
                    ProblemComplexity.SIMPLE: 1.0,
                    ProblemComplexity.MEDIUM: 1.5,
                    ProblemComplexity.COMPLEX: 2.0,
                    ProblemComplexity.VERY_COMPLEX: 2.5
                }

                adjusted_iter = int(
                    base_iterations * complexity_multiplier.get(complexity, 1.5))
                max_iter = min(adjusted_iter, max_safe_iterations)

                # ğŸ†• æ£€æŸ¥è‡ªåŠ¨æ‰©å±•æ¡ä»¶
                auto_extension_conditions = intelligent_config.get(
                    "auto_extension_conditions", [])
                file_generation_keywords = [
                    "ç”Ÿæˆ", "ä¿å­˜", "åˆ›å»º", "save", "create", ".md", ".pdf", ".doc", ".txt"]

                extension_needed = False
                if "file_generation_required" in auto_extension_conditions:
                    if any(keyword in user_message.lower() for keyword in file_generation_keywords):
                        extension_needed = True
                        print("ğŸ”„ æ£€æµ‹åˆ°æ–‡ä»¶ç”Ÿæˆéœ€æ±‚ï¼Œå¯ç”¨æ™ºèƒ½æ‰©å±•")

                if "complex_calculation_required" in auto_extension_conditions:
                    calc_keywords = ["è®¡ç®—", "ç®—", "ä¹˜", "é™¤",
                                     "åŠ ", "å‡", "æ±‚", "math", "calculate"]
                    if any(keyword in user_message.lower() for keyword in calc_keywords):
                        extension_needed = True
                        print("ğŸ”„ æ£€æµ‹åˆ°å¤æ‚è®¡ç®—éœ€æ±‚ï¼Œå¯ç”¨æ™ºèƒ½æ‰©å±•")

                if extension_needed:
                    max_iter = min(max_iter + 5, max_safe_iterations)  # é¢å¤–å¢åŠ 5è½®
                    print(f"ğŸ”„ æ™ºèƒ½æ‰©å±•è¿­ä»£æ¬¡æ•°è‡³: {max_iter}")

            elif control_mode == "flexible":
                # çµæ´»æ¨¡å¼ï¼šåªæœ‰å®‰å…¨ä¸Šé™ï¼Œä¸»è¦ä¾èµ–LLMåˆ¤æ–­
                max_iter = getattr(config, 'INTELLIGENT_ADJUSTMENT_CONFIG', {}).get(
                    "max_safe_iterations", 20)
                print(f"ğŸ”„ çµæ´»æ¨¡å¼ï¼šæœ€å¤§å®‰å…¨è¿­ä»£æ¬¡æ•° {max_iter}")

            else:
                # é»˜è®¤ä½¿ç”¨ç­–ç•¥é…ç½®
                strategy_config = strategy_manager.strategy_configs[strategy]
                max_iter = strategy_config["max_iterations"]

            # ğŸ†• åŸæœ‰çš„åŠ¨æ€æ‰©å±•é€»è¾‘ï¼ˆä»…åœ¨éä¸¥æ ¼æ¨¡å¼ä¸‹ç”Ÿæ•ˆï¼‰
            if control_mode != "strict" and state.get("dynamic_iteration_extension", True):
                # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡ä»¶ç”Ÿæˆç­‰å¤æ‚è¦æ±‚
                file_generation_keywords = [
                    "ç”Ÿæˆ", "ä¿å­˜", "åˆ›å»º", "save", "create", ".md", ".pdf", ".doc", ".txt"]
                has_complex_requirements = any(
                    keyword in user_message.lower() for keyword in file_generation_keywords)

                if has_complex_requirements or complexity in [ProblemComplexity.COMPLEX, ProblemComplexity.VERY_COMPLEX]:
                    # æ ¹æ®å¤æ‚åº¦å’Œé¢„ä¼°æ­¥éª¤æ•°åŠ¨æ€è°ƒæ•´
                    dynamic_iterations = max(
                        max_iter,
                        complexity_result.estimated_steps + 2,  # é¢„ä¼°æ­¥éª¤æ•°åŠ 2ä¸ªç¼“å†²è½®æ¬¡
                        config.MAX_DYNAMIC_ITERATIONS if hasattr(
                            config, 'MAX_DYNAMIC_ITERATIONS') else 15
                    )

                    # æ ¹æ®æ§åˆ¶æ¨¡å¼ç¡®å®šä¸Šé™
                    if control_mode == "intelligent":
                        upper_limit = getattr(config, 'INTELLIGENT_ADJUSTMENT_CONFIG', {}).get(
                            "max_safe_iterations", 20)
                    else:  # flexible
                        upper_limit = 25  # çµæ´»æ¨¡å¼å…è®¸æ›´å¤šè½®æ¬¡

                    dynamic_iterations = min(dynamic_iterations, upper_limit)

                    if dynamic_iterations > max_iter:
                        print(
                            f"ğŸ”„ åŠ¨æ€æ‰©å±•è¿­ä»£æ¬¡æ•°: {max_iter} -> {dynamic_iterations} (å¤æ‚ä»»åŠ¡éœ€è¦)")
                        max_iter = dynamic_iterations

            state["max_iterations"] = max_iter
            print(f"ğŸ”§ è¿­ä»£æ§åˆ¶æ¨¡å¼: {control_mode} | æœ€å¤§è¿­ä»£æ¬¡æ•°: {max_iter}")
        else:
            # ç¦ç”¨è‡ªåŠ¨è°ƒæ•´æ—¶ä½¿ç”¨é»˜è®¤å€¼
            max_iter = config.DEFAULT_MAX_ITERATIONS

        # æ›´æ–°çŠ¶æ€ä¸­çš„ç­–ç•¥ä¿¡æ¯
        state["reasoning_strategy"] = strategy.value
        state["problem_complexity"] = complexity.value
        state["recommended_tools"] = recommended_tools
        state["success_criteria"] = complexity_result.success_criteria
        success_criteria = complexity_result.success_criteria
    else:
        # ä»çŠ¶æ€ä¸­æ¢å¤ç­–ç•¥ä¿¡æ¯
        strategy = ReasoningStrategy(
            state.get("reasoning_strategy", "sequential"))
        complexity = ProblemComplexity(
            state.get("problem_complexity", "medium"))
        recommended_tools = state.get("recommended_tools", [])
        success_criteria = state.get("success_criteria", "å®Œæˆé—®é¢˜è§£ç­”")

    if current_iter >= max_iter:
        # ğŸ†• åœ¨æ™ºèƒ½æ¨¡å¼ä¸‹ï¼Œæ£€æŸ¥æ˜¯å¦çœŸçš„éœ€è¦åœæ­¢
        control_mode = getattr(config, 'ITERATION_CONTROL_MODE', 'intelligent')

        if control_mode == "intelligent":
            # æ™ºèƒ½æ¨¡å¼ï¼šæ£€æŸ¥ä»»åŠ¡å®Œæˆåº¦å’Œè¿›å±•æƒ…å†µ
            intelligent_config = getattr(
                config, 'INTELLIGENT_ADJUSTMENT_CONFIG', {})
            max_safe_iterations = intelligent_config.get(
                "max_safe_iterations", 20)

            # å¦‚æœè¿˜æ²¡è¾¾åˆ°å®‰å…¨ä¸Šé™ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰ç»§ç»­çš„å¿…è¦
            if current_iter < max_safe_iterations:
                # æ£€æŸ¥æœ€è¿‘çš„æ¨ç†è¿›å±•
                reasoning_chain = state.get("reasoning_chain", [])
                if len(reasoning_chain) >= 2:
                    # æ£€æŸ¥æœ€è¿‘å‡ è½®æ˜¯å¦æœ‰å®è´¨æ€§è¿›å±•
                    recent_actions = reasoning_chain[-2:]
                    has_meaningful_progress = any(
                        step.get('observation') and
                        step['observation'] != "ç­‰å¾…å·¥å…·æ‰§è¡Œç»“æœ..." and
                        len(step['observation']) > 50
                        for step in recent_actions
                    )

                    if has_meaningful_progress:
                        print(f"ğŸ”„ æ™ºèƒ½æ¨¡å¼æ£€æµ‹åˆ°è¿›å±•ï¼Œå»¶é•¿æ¨ç†è‡³ç¬¬ {current_iter + 1} è½®")
                        # ä¸´æ—¶æ‰©å±•ä¸€è½®ï¼Œè®©LLMåˆ¤æ–­æ˜¯å¦éœ€è¦ç»§ç»­
                        state["max_iterations"] = current_iter + 2
                        max_iter = current_iter + 2
                    else:
                        print(f"â° æ™ºèƒ½æ¨¡å¼æ£€æµ‹åˆ°è¿›å±•åœæ»ï¼Œç»“æŸæ¨ç†")
                        final_answer = f"åŸºäº{max_iter}è½®æ¨ç†çš„ç»“æœï¼Œæœªèƒ½åœ¨å½“å‰è½®æ¬¡å†…å®Œå…¨è§£å†³é—®é¢˜"
                        ai_message = AIMessage(content=final_answer)
                        return {
                            **state,
                            "messages": state["messages"] + [ai_message],
                            "next_action": "end"
                        }
                else:
                    print(f"â° è¾¾åˆ°ç­–ç•¥é™åˆ¶è½®æ¬¡({max_iter})ï¼Œä½†æ™ºèƒ½æ¨¡å¼å…è®¸ç»§ç»­")
                    # å…è®¸ç»§ç»­ï¼Œä½†æé†’æ¥è¿‘é™åˆ¶
                    if current_iter < max_safe_iterations:
                        state["max_iterations"] = current_iter + 3  # å†ç»™3è½®æœºä¼š
                        max_iter = current_iter + 3
            else:
                print(f"â° è¾¾åˆ°å®‰å…¨ä¸Šé™({max_safe_iterations})ï¼Œå¼ºåˆ¶ç»“æŸæ¨ç†")
                final_answer = f"å·²è¾¾åˆ°å®‰å…¨ä¸Šé™({max_safe_iterations})è½®ï¼ŒåŸºäºå·²æœ‰ä¿¡æ¯æä¾›ç­”æ¡ˆ"
                ai_message = AIMessage(content=final_answer)
                return {
                    **state,
                    "messages": state["messages"] + [ai_message],
                    "next_action": "end"
                }

        elif control_mode == "flexible":
            # çµæ´»æ¨¡å¼ï¼šä¸»è¦ä¾èµ–LLMåˆ¤æ–­ï¼Œåªæœ‰å®‰å…¨ä¸Šé™
            flexible_limit = getattr(config, 'INTELLIGENT_ADJUSTMENT_CONFIG', {}).get(
                "max_safe_iterations", 20)
            if current_iter >= flexible_limit:
                print(f"â° çµæ´»æ¨¡å¼è¾¾åˆ°å®‰å…¨ä¸Šé™({flexible_limit})ï¼Œç»“æŸæ¨ç†")
                final_answer = f"å·²è¾¾åˆ°å®‰å…¨ä¸Šé™({flexible_limit})è½®ï¼ŒåŸºäºå·²æœ‰ä¿¡æ¯æä¾›ç­”æ¡ˆ"
                ai_message = AIMessage(content=final_answer)
                return {
                    **state,
                    "messages": state["messages"] + [ai_message],
                    "next_action": "end"
                }
            else:
                print(f"ğŸ”„ çµæ´»æ¨¡å¼å…è®¸ç»§ç»­æ¨ç† (ç¬¬ {current_iter + 1} è½®)")
                # ä¸å¼ºåˆ¶åœæ­¢ï¼Œè®©LLMå†³å®š

        else:  # strict mode
            print(f"â° ä¸¥æ ¼æ¨¡å¼è¾¾åˆ°æœ€å¤§è½®æ¬¡({max_iter})ï¼Œç»“æŸæ¨ç†")
            ai_message = AIMessage(
                content=f"å·²è¾¾åˆ°æœ€å¤§æ¨ç†è½®æ¬¡({max_iter})ï¼Œç»“æŸæ€è€ƒè¿‡ç¨‹ã€‚\n\nåŸºäºå·²æœ‰ä¿¡æ¯ï¼Œæˆ‘çš„æœ€ç»ˆç­”æ¡ˆæ˜¯:\n{state.get('final_answer', 'æŠ±æ­‰ï¼Œæ— æ³•åœ¨é™å®šè½®æ¬¡å†…å®Œå…¨è§£å†³è¿™ä¸ªé—®é¢˜ã€‚')}"
            )
            return {
                **state,
                "messages": state["messages"] + [ai_message],
                "next_action": "end"
            }

    # ğŸ†• æ„å»ºæ¨ç†ä¸Šä¸‹æ–‡å¯¹è±¡
    available_tools = get_react_tools()
    available_tool_names = [tool.name for tool in available_tools]
    used_tools = state.get("tools_used", [])

    reasoning_context = ReasoningContext(
        problem=user_message,
        complexity=complexity,
        strategy=strategy,
        max_iterations=max_iter,
        current_iteration=current_iter,
        reasoning_chain=state.get("reasoning_chain", []),
        available_tools=available_tool_names,
        used_tools=used_tools,
        confidence_threshold=strategy_manager.strategy_configs[strategy]["confidence_threshold"],
        recommended_tools=recommended_tools
    )

    # ğŸ†• è¯„ä¼°æ¨ç†è¿›å±•
    progress_evaluation = strategy_manager.evaluate_reasoning_progress(
        reasoning_context)
    print(
        f"ğŸ“ˆ è¿›å±•: {progress_evaluation['progress_score']:.2f} | ä¿¡å¿ƒ: {progress_evaluation['confidence']:.2f}")

    # å¦‚æœé…ç½®äº†LLMï¼Œä½¿ç”¨æ™ºèƒ½æ¨ç†
    if llm:
        try:
            # ç”Ÿæˆå·¥å…·æ–‡æ¡£
            tool_docs = mcp_adapter.generate_tool_documentation()

            # ğŸ†• ä½¿ç”¨ç­–ç•¥ç®¡ç†å™¨ç”Ÿæˆæ™ºèƒ½æç¤ºè¯
            strategy_prompt = strategy_manager.generate_strategy_prompt(
                reasoning_context)

            # ğŸ†• è·å–ä¸‹ä¸€æ­¥è¡ŒåŠ¨å»ºè®®
            action_suggestions = strategy_manager.suggest_next_action(
                reasoning_context, progress_evaluation)

            # ğŸ†• è®¡ç®—å½“å‰æ¨ç†é˜¶æ®µ
            progress_ratio = current_iter / max_iter if max_iter > 0 else 0
            if progress_ratio < 0.4:
                current_stage = "early_stage"
                stage_description = "ä¿¡æ¯æ”¶é›†å’Œé—®é¢˜åˆ†æé˜¶æ®µ"
                stage_priority = "é‡ç‚¹è¿›è¡Œé—®é¢˜åˆ†æã€ä¿¡æ¯æœç´¢å’ŒåŸºç¡€è®¡ç®—"
            elif progress_ratio < 0.8:
                current_stage = "middle_stage"
                stage_description = "ä¿¡æ¯å¤„ç†å’Œå†…å®¹ç”Ÿæˆé˜¶æ®µ"
                stage_priority = "é‡ç‚¹è¿›è¡Œå†…å®¹ç”Ÿæˆã€æ–‡æœ¬å¤„ç†å’Œæ•°æ®éªŒè¯"
            else:
                current_stage = "late_stage"
                stage_description = "æœ€ç»ˆè¾“å‡ºå’ŒæŠ¥å‘Šç”Ÿæˆé˜¶æ®µ"
                stage_priority = "é‡ç‚¹è¿›è¡ŒæŠ¥å‘Šç”Ÿæˆã€æ ¼å¼åŒ–å’Œæ–‡ä»¶ä¿å­˜"

            prompt = f"""
{strategy_prompt}

å¯ç”¨çš„å·¥å…·:
{tool_docs}

ğŸ“Š å½“å‰æ¨ç†çŠ¶æ€:
- è¿›å±•åˆ†æ•°: {progress_evaluation['progress_score']}
- ä¿¡å¿ƒåº¦: {progress_evaluation['confidence']}
- å·¥å…·å¤šæ ·æ€§: {progress_evaluation['tool_diversity']}
- æ¨ç†é˜¶æ®µ: {stage_description}

ğŸ’¡ æ¨ç†å»ºè®®:
- æ¨ç†ç„¦ç‚¹: {action_suggestions['reasoning_focus']}
- æ¨èå·¥å…·: {', '.join(action_suggestions['recommended_tools'][:3])}
- è¡ŒåŠ¨ç±»å‹: {action_suggestions['action_type']}

ğŸ¯ æ¨èå·¥å…·: {', '.join(recommended_tools)} (åŸºäºé—®é¢˜å¤æ‚åº¦åˆ†æå¾—å‡º)
âœ… æˆåŠŸæ ‡å‡†: {success_criteria}

âš ï¸ å½“å‰é˜¶æ®µé‡ç‚¹: {stage_priority}

ğŸ“‹ å·¥å…·ä½¿ç”¨æŒ‡å¯¼:
- å¦‚æœç”¨æˆ·è¦æ±‚ç”Ÿæˆæ–‡ä»¶æˆ–æŠ¥å‘Šï¼Œè¯·åœ¨æ”¶é›†è¶³å¤Ÿä¿¡æ¯åå†è¿›è¡Œ
- æŠ¥å‘Šç”Ÿæˆå·¥å…·(å¦‚create_markdown_report)åº”è¯¥åœ¨æœ€åé˜¶æ®µä½¿ç”¨
- å…ˆé€šè¿‡å…¶ä»–å·¥å…·æ”¶é›†å’Œå¤„ç†ä¿¡æ¯ï¼Œå†è¿›è¡Œæœ€ç»ˆçš„æ ¼å¼åŒ–è¾“å‡º

è¯·åˆ†æé—®é¢˜å¹¶å†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨ï¼š

æ ¸å¿ƒç›®æ ‡ï¼šç†è§£ç”¨æˆ·çš„çœŸå®éœ€æ±‚å¹¶æ‰¾åˆ°æœ€ä½³è§£å†³æ–¹æ¡ˆ

æ€è€ƒè¦ç‚¹ï¼š
1. ç”¨æˆ·æƒ³è¦ä»€ä¹ˆæ ·çš„ç»“æœï¼Ÿ
2. ç”¨æˆ·æœ‰ä»€ä¹ˆå…·ä½“çš„è¦æ±‚æˆ–æœŸæœ›ï¼Ÿ
3. ç°åœ¨å·²ç»è·å¾—çš„ä¿¡æ¯æ˜¯å¦è¶³å¤Ÿå›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼Ÿ
4. æ˜¯å¦æ»¡è¶³äº†ä¸Šè¿°æˆåŠŸæ ‡å‡†çš„æ‰€æœ‰è¦æ±‚ï¼Ÿ
5. ç”¨æˆ·æ˜¯å¦è¦æ±‚ç‰¹å®šçš„è¾“å‡ºæ ¼å¼æˆ–æ–‡ä»¶ç”Ÿæˆï¼Ÿ
6. å¦‚æœä¸å¤Ÿï¼Œè¿˜éœ€è¦ä»€ä¹ˆä¿¡æ¯æˆ–æ“ä½œï¼Ÿ

åˆ¤æ–­å®Œæˆçš„æ ‡å‡†ï¼š
- ä¸ä»…è¦æœ‰è¶³å¤Ÿçš„ä¿¡æ¯ï¼Œè¿˜è¦ç¡®ä¿å®Œæˆäº†ç”¨æˆ·çš„æ‰€æœ‰å…·ä½“è¦æ±‚
- ç‰¹åˆ«æ³¨æ„ç”¨æˆ·æ˜¯å¦è¦æ±‚ç”Ÿæˆæ–‡ä»¶ã€æŠ¥å‘Šæˆ–ç‰¹å®šæ ¼å¼çš„è¾“å‡º
- ç¡®ä¿æ¯ä¸ªæ­¥éª¤éƒ½æŒ‰ç”¨æˆ·è¦æ±‚æ‰§è¡Œå®Œæ¯•

ä½ å¯ä»¥ï¼š
- ä½¿ç”¨å·¥å…·è·å–æ›´å¤šä¿¡æ¯
- ä½¿ç”¨å·¥å…·ç”Ÿæˆç”¨æˆ·è¦æ±‚çš„è¾“å‡ºæ ¼å¼
- åŸºäºå·²æœ‰ä¿¡æ¯ç»™å‡ºæœ€ç»ˆç­”æ¡ˆï¼ˆä»…å½“çœŸæ­£å®Œæˆæ‰€æœ‰è¦æ±‚æ—¶ï¼‰

å·¥å…·é€‰æ‹©å»ºè®®ï¼š
- æ ¹æ®å®é™…éœ€è¦é€‰æ‹©åˆé€‚çš„å·¥å…·
- æ•°å­¦è®¡ç®—å»ºè®®ä½¿ç”¨calculate_mathå·¥å…·ç¡®ä¿å‡†ç¡®æ€§
- æ—¶é—´ç›¸å…³ä¿¡æ¯å»ºè®®ä½¿ç”¨æ—¶é—´å·¥å…·è·å–å‡†ç¡®æ•°æ®
- å¦‚æœç”¨æˆ·è¦æ±‚ç‰¹å®šæ ¼å¼è¾“å‡ºï¼Œå¿…é¡»ä½¿ç”¨ç›¸åº”çš„æ ¼å¼åŒ–å·¥å…·

è¯·ç”¨JSONæ ¼å¼è¿”å›ä½ çš„å†³å®š:
{{
    "thought": "è¯¦ç»†çš„æ€è€ƒè¿‡ç¨‹å’Œåˆ†æ",
    "action": "ä¸‹ä¸€æ­¥è¡ŒåŠ¨çš„å…·ä½“æè¿°",
    "tool_name": "å·¥å…·åç§°(å¦‚æœéœ€è¦ä½¿ç”¨å·¥å…·)",
    "tool_args": {{"å‚æ•°å": "å‚æ•°å€¼"}},
    "need_more_info": true/false,
    "final_answer": "æœ€ç»ˆç­”æ¡ˆ(å¦‚æœå·²ç»å¯ä»¥ç»™å‡ºå®Œæ•´ç­”æ¡ˆ)"
}}

åªè¿”å›JSONæ ¼å¼å†…å®¹ã€‚"""

            print(f"ğŸ¤– å‘LLMå‘é€æç¤ºè¯:")
            if current_iter == 0:  # åªåœ¨ç¬¬ä¸€è½®æ‰“å°æ ¸å¿ƒé—®é¢˜
                print(f"â“ æ ¸å¿ƒé—®é¢˜: {user_message}")
            print(f"ğŸ“ æç¤ºè¯é•¿åº¦: {len(prompt)} å­—ç¬¦")

            response = await llm.ainvoke([HumanMessage(content=prompt)])

            # è§£æLLMå“åº”
            import json
            try:
                content = str(response.content).strip()
                if content.startswith('```json'):
                    content = content[7:]
                if content.endswith('```'):
                    content = content[:-3]

                reasoning = json.loads(content.strip())
                thought = reasoning.get("thought", "æ€è€ƒä¸­...")
                action = reasoning.get("action", "æ‰§è¡Œæ“ä½œ")
                tool_name = reasoning.get("tool_name", "")
                tool_args = reasoning.get("tool_args", {})
                need_more_info = reasoning.get("need_more_info", True)
                final_answer = reasoning.get("final_answer", "")

                print(f"ğŸ’­ LLMæ€è€ƒ: {thought[:100]}...")
                print(f"ğŸ¯ å†³ç­–: {action}")

                # æ£€æŸ¥æ˜¯å¦å®Œæˆæ¨ç† - è®©LLMè‡ªä¸»åˆ¤æ–­ä»»åŠ¡å®Œæˆ
                if not need_more_info and not tool_name:
                    print("âœ… æ¨ç†å®Œæˆ")
                    final_answer = final_answer or thought

                    ai_message = AIMessage(
                        content=f"æ€è€ƒå®Œæˆï¼\n\næ€è·¯: {thought}\n\næœ€ç»ˆç­”æ¡ˆ: {final_answer}"
                    )

                    reasoning_chain = state.get("reasoning_chain", [])
                    return {
                        **state,
                        "messages": state["messages"] + [ai_message],
                        "final_answer": final_answer,
                        "thought_process": state["thought_process"] + [thought],
                        "reasoning_chain": reasoning_chain,
                        "next_action": "end"
                    }

                # å¦‚æœLLMæŒ‡å®šäº†å·¥å…·ï¼Œæ— è®ºneed_more_infoå¦‚ä½•éƒ½åº”è¯¥å…ˆæ‰§è¡Œå·¥å…·
                if tool_name:
                    print(f"ğŸ”§ è°ƒç”¨å·¥å…·: {tool_name}")
                    tool_name = resolve_tool_name(tool_name)
                    tool_args = resolve_params(tool_name, tool_args)
                    print(f"ğŸ“‹ å·¥å…·å‚æ•°: {tool_args}")

                    # åˆ›å»ºå·¥å…·è°ƒç”¨
                    tool_call = {
                        "name": tool_name,
                        "args": tool_args,
                        "id": f"call_react_{current_iter + 1}"
                    }

                    ai_message = AIMessage(
                        content=f"ç¬¬{current_iter + 1}è½®æ¨ç†:\n\nğŸ¤” æ€è€ƒ: {thought}\n\nğŸ”§ è¡ŒåŠ¨: ä½¿ç”¨ {tool_name} å·¥å…·",
                        tool_calls=[tool_call]
                    )

                    # æ›´æ–°æ¨ç†é“¾
                    reasoning_chain = state.get("reasoning_chain", [])
                    reasoning_chain.append({
                        "thought": thought,
                        "action": f"ä½¿ç”¨ {tool_name} å·¥å…·",
                        "observation": "ç­‰å¾…å·¥å…·æ‰§è¡Œç»“æœ..."
                    })

                    return {
                        **state,
                        "messages": state["messages"] + [ai_message],
                        "thought_process": state["thought_process"] + [thought],
                        "reasoning_chain": reasoning_chain,
                        "current_iteration": current_iter + 1,
                        "next_action": "execute_tools"
                    }

                else:
                    print("âŒ LLMæ²¡æœ‰æŒ‡å®šå·¥å…·æˆ–æ˜ç¡®å®Œæˆï¼Œç»§ç»­æ¨ç†")
                    ai_message = AIMessage(
                        content=f"ç¬¬{current_iter + 1}è½®æ¨ç†:\n\nğŸ¤” æ€è€ƒ: {thought}\n\nğŸ“ è¡ŒåŠ¨: {action}\n\nç»§ç»­æ¨ç†..."
                    )

                    return {
                        **state,
                        "messages": state["messages"] + [ai_message],
                        "thought_process": state["thought_process"] + [thought],
                        "current_iteration": current_iter + 1,
                        "next_action": "continue_reasoning"
                    }

            except (json.JSONDecodeError, KeyError) as e:
                print(f"âŒ è§£æLLMå“åº”å¤±è´¥: {e}")
                ai_message = AIMessage(
                    content=f"ç¬¬{current_iter + 1}è½®æ¨ç†å¤±è´¥ï¼ŒJSONè§£æé”™è¯¯: {e}"
                )
                return {
                    **state,
                    "messages": state["messages"] + [ai_message],
                    "current_iteration": current_iter + 1,
                    "next_action": "continue_reasoning"
                }

        except Exception as e:
            print(f"âŒ LLMè°ƒç”¨å¤±è´¥: {e}")
            ai_message = AIMessage(
                content=f"ç¬¬{current_iter + 1}è½®æ¨ç†å¤±è´¥: {str(e)}"
            )
            return {
                **state,
                "messages": state["messages"] + [ai_message],
                "current_iteration": current_iter + 1,
                "next_action": "continue_reasoning"
            }

    else:
        print("âš ï¸ æœªé…ç½®LLMï¼Œæ— æ³•è¿›è¡Œæ¨ç†")
        ai_message = AIMessage(content="æœªé…ç½®LLMï¼Œæ— æ³•è¿›è¡Œæ¨ç†")
        return {
            **state,
            "messages": state["messages"] + [ai_message],
            "next_action": "end"
        }


async def react_executor_agent(state: 'ReActState') -> 'ReActState':
    """ReActæ‰§è¡Œæ™ºèƒ½ä½“ - è´Ÿè´£å¤„ç†å·¥å…·æ‰§è¡Œç»“æœ"""

    print(f"\nğŸ”§ [æ­¥éª¤{state.get('current_iteration', 0)}] å¤„ç†å·¥å…·ç»“æœ...")

    # è·å–æœ€åä¸€æ¡æ¶ˆæ¯ï¼ˆå·¥å…·æ‰§è¡Œç»“æœï¼‰
    last_message = state["messages"][-1]
    tool_output = str(last_message.content)  # ç¡®ä¿æ˜¯å­—ç¬¦ä¸²ç±»å‹

    # æ˜¾ç¤ºå·¥å…·æ‰§è¡Œç»“æœæ‘˜è¦
    if len(tool_output) > 200:
        result_summary = tool_output[:200] + "..."
    else:
        result_summary = tool_output

    print(f"ğŸ“‹ å·¥å…·æ‰§è¡Œç»“æœ: {result_summary}")

    # æ›´æ–°æ¨ç†é“¾ä¸­çš„è§‚å¯Ÿç»“æœ
    reasoning_chain = state.get("reasoning_chain", [])
    if reasoning_chain:
        reasoning_chain[-1]["observation"] = tool_output

    # è·å–å½“å‰é—®é¢˜å’Œä¸Šä¸‹æ–‡
    current_problem = state.get("current_problem", "")
    current_iter = state.get("current_iteration", 0)
    max_iter = state.get("max_iterations", config.DEFAULT_MAX_ITERATIONS)
    reached_max_iter = current_iter >= max_iter

    # ğŸ†• æ–‡ä»¶å­˜åœ¨æ€§æ£€æŸ¥å‡½æ•°
    def check_file_requirements(problem: str, tool_output: str) -> Dict[str, Any]:
        """æ£€æŸ¥æ–‡ä»¶ç”Ÿæˆè¦æ±‚æ˜¯å¦æ»¡è¶³"""
        import os
        import re

        # æ£€æµ‹æ–‡ä»¶ç”Ÿæˆè¦æ±‚
        file_generation_keywords = ["ç”Ÿæˆ", "ä¿å­˜", "åˆ›å»º", "save", "create"]
        file_extension_pattern = r'\.(md|pdf|doc|docx|txt|json|xml|html|csv|xlsx)(?:\s|$|ï¼Œ|ã€‚|ï¼|ï¼Ÿ)'

        has_file_requirement = any(keyword in problem.lower()
                                   for keyword in file_generation_keywords)
        file_extensions = re.findall(file_extension_pattern, problem.lower())

        # ä»é—®é¢˜ä¸­æå–å¯èƒ½çš„æ–‡ä»¶å
        potential_filenames = []

        # åŒ¹é… "ä¿å­˜ä¸º filename.ext" æˆ– "save as filename.ext" æ¨¡å¼
        # æ”¯æŒä¸­æ–‡æ–‡ä»¶åçš„æ­£åˆ™è¡¨è¾¾å¼
        filename_patterns = [
            r'ä¿å­˜ä¸º\s+([^\s]+\.[a-zA-Z0-9]+)',
            r'save\s+as\s+([^\s]+\.[a-zA-Z0-9]+)',
            r'åˆ›å»º\s+([^\s]+\.[a-zA-Z0-9]+)',
            r'create\s+([^\s]+\.[a-zA-Z0-9]+)',
            r'ç”Ÿæˆ\s+([^\s]+\.[a-zA-Z0-9]+)',
            r'([^\s]+\.[a-zA-Z0-9]+)(?:\s|$|ï¼Œ|ã€‚)'
        ]

        for pattern in filename_patterns:
            matches = re.findall(pattern, problem, re.IGNORECASE)
            potential_filenames.extend(matches)

        # ä»å·¥å…·è¾“å‡ºä¸­æå–å¯èƒ½åˆ›å»ºçš„æ–‡ä»¶
        output_filenames = []
        output_patterns = [
            r'æ–‡ä»¶å·²ä¿å­˜ä¸º[ï¼š:\s]+([^\s]+\.[a-zA-Z0-9]+)',
            r'æ–‡ä»¶å·²ä¿å­˜åˆ°[ï¼š:\s]+([^\s]+\.[a-zA-Z0-9]+)',
            r'å·²ä¿å­˜åˆ°[ï¼š:\s]+([^\s]+\.[a-zA-Z0-9]+)',
            r'æ–‡ä»¶å·²åˆ›å»º[ï¼š:\s]+([^\s]+\.[a-zA-Z0-9]+)',
            r'saved as[ï¼š:\s]+([^\s]+\.[a-zA-Z0-9]+)',
            r'saved to[ï¼š:\s]+([^\s]+\.[a-zA-Z0-9]+)',
            r'created[ï¼š:\s]+([^\s]+\.[a-zA-Z0-9]+)',
            r'æ–‡ä»¶è·¯å¾„[ï¼š:\s]+([^\s]+\.[a-zA-Z0-9]+)',
            r'file path[ï¼š:\s]+([^\s]+\.[a-zA-Z0-9]+)',
            r'file_path[\"\':\s]+([^\s\"\']+\.[a-zA-Z0-9]+)'
        ]

        for pattern in output_patterns:
            matches = re.findall(pattern, tool_output, re.IGNORECASE)
            output_filenames.extend(matches)

        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦çœŸçš„å­˜åœ¨
        existing_files = []
        missing_files = []

        all_potential_files = list(set(potential_filenames + output_filenames))

        for filename in all_potential_files:
            if os.path.exists(filename):
                existing_files.append(filename)
            else:
                missing_files.append(filename)

        return {
            "has_file_requirement": has_file_requirement,
            "file_extensions": file_extensions,
            "potential_filenames": potential_filenames,
            "output_filenames": output_filenames,
            "existing_files": existing_files,
            "missing_files": missing_files,
            "requirement_satisfied": has_file_requirement and len(existing_files) > 0
        }

    # å¦‚æœé…ç½®äº†LLMï¼Œè®©LLMåˆ¤æ–­æ˜¯å¦ç»§ç»­æ¨ç†
    if llm:
        try:
            # æ„å»ºæ¨ç†ä¸Šä¸‹æ–‡
            context = f"é—®é¢˜: {current_problem}\n\n"
            if reasoning_chain:
                context += "æ¨ç†è¿‡ç¨‹:\n"
                for i, step in enumerate(reasoning_chain, 1):
                    context += f"ç¬¬{i}è½®:\n"
                    context += f"æ€è€ƒ: {step.get('thought', '')}\n"
                    context += f"è¡ŒåŠ¨: {step.get('action', '')}\n"
                    context += f"è§‚å¯Ÿ: {step.get('observation', '')}\n\n"

            # ğŸ†• æ‰§è¡Œæ–‡ä»¶æ£€æŸ¥
            file_check_result = check_file_requirements(
                current_problem, tool_output)

            # å¦‚æœè¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œéœ€è¦ç»™å‡ºæœ€ç»ˆç­”æ¡ˆ
            if reached_max_iter:
                prompt = f"""
â° å·²è¾¾åˆ°æœ€å¤§æ¨ç†è½®æ¬¡({max_iter})ï¼Œç°åœ¨éœ€è¦ç»™å‡ºæœ€ç»ˆç­”æ¡ˆã€‚

{context}

æœ€æ–°çš„å·¥å…·æ‰§è¡Œç»“æœ: {tool_output}

ğŸ—‚ï¸ æ–‡ä»¶ç”Ÿæˆæ£€æŸ¥ç»“æœ:
- æ˜¯å¦æœ‰æ–‡ä»¶ç”Ÿæˆè¦æ±‚: {file_check_result['has_file_requirement']}
- æœŸæœ›çš„æ–‡ä»¶: {file_check_result['potential_filenames']}
- è¾“å‡ºä¸­æåˆ°çš„æ–‡ä»¶: {file_check_result['output_filenames']}
- å®é™…å­˜åœ¨çš„æ–‡ä»¶: {file_check_result['existing_files']}
- ç¼ºå¤±çš„æ–‡ä»¶: {file_check_result['missing_files']}

è¯·åŸºäºå·²è·å¾—çš„æ‰€æœ‰ä¿¡æ¯ç»™å‡ºæœ€ç»ˆç­”æ¡ˆã€‚æ ¹æ®ä½ çš„åˆ†æï¼Œå°½åŠ›ç»™å‡ºæœ€ä½³çš„ç­”æ¡ˆã€‚

è¯·ç”¨JSONæ ¼å¼è¿”å›ä½ çš„å†³å®š:
{{
    "analysis": "å¯¹å½“å‰ç»“æœçš„åˆ†æ",
    "is_complete": true,
    "final_answer": "åŸºäºå·²æœ‰ä¿¡æ¯çš„æœ€ç»ˆç­”æ¡ˆ",
    "next_step": "æ— "
}}

åªè¿”å›JSONæ ¼å¼å†…å®¹ã€‚"""
            else:
                # è·å–æˆåŠŸæ ‡å‡†
                success_criteria = state.get("success_criteria", "å®Œæˆé—®é¢˜è§£ç­”")

                prompt = f"""
å½“å‰æ˜¯ç¬¬{current_iter}è½®æ¨ç†çš„ç»“æœåˆ†æã€‚

{context}

æœ€æ–°çš„å·¥å…·æ‰§è¡Œç»“æœ: {tool_output}

âœ… æˆåŠŸæ ‡å‡†: {success_criteria}

ğŸ—‚ï¸ æ–‡ä»¶ç”Ÿæˆæ£€æŸ¥ç»“æœ:
- æ˜¯å¦æœ‰æ–‡ä»¶ç”Ÿæˆè¦æ±‚: {file_check_result['has_file_requirement']}
- æœŸæœ›çš„æ–‡ä»¶: {file_check_result['potential_filenames']}
- è¾“å‡ºä¸­æåˆ°çš„æ–‡ä»¶: {file_check_result['output_filenames']}
- å®é™…å­˜åœ¨çš„æ–‡ä»¶: {file_check_result['existing_files']}
- ç¼ºå¤±çš„æ–‡ä»¶: {file_check_result['missing_files']}
- æ–‡ä»¶è¦æ±‚æ˜¯å¦æ»¡è¶³: {file_check_result['requirement_satisfied']}

è¯·åˆ†æå½“å‰æƒ…å†µå¹¶å†³å®šä¸‹ä¸€æ­¥ï¼š

**ğŸ” ä¸¥æ ¼æ£€æŸ¥æ¸…å•ï¼š**
1. ç”¨æˆ·çš„åŸå§‹é—®é¢˜æ˜¯ä»€ä¹ˆï¼Ÿ
2. ç”¨æˆ·æ˜¯å¦æ˜ç¡®è¦æ±‚äº†ç‰¹å®šçš„è¾“å‡ºæ ¼å¼æˆ–æ–‡ä»¶ï¼Ÿ
3. æ˜¯å¦éœ€è¦ç”Ÿæˆæ–‡ä»¶æˆ–æŠ¥å‘Šï¼Ÿå¦‚æœæ˜¯ï¼Œæ–‡ä»¶æ˜¯å¦å·²ç»å®é™…å­˜åœ¨ï¼Ÿ
4. æ˜¯å¦éœ€è¦ä¿å­˜åˆ°ç‰¹å®šæ–‡ä»¶åï¼Ÿå¦‚æœæ˜¯ï¼Œè¯¥æ–‡ä»¶æ˜¯å¦å·²ç»å­˜åœ¨ï¼Ÿ
5. æ‰€æœ‰ç”¨æˆ·æ˜ç¡®æå‡ºçš„è¦æ±‚æ˜¯å¦éƒ½å·²ç»æ»¡è¶³ï¼Ÿ

**â—ï¸ ç‰¹åˆ«æ³¨æ„ - æ–‡ä»¶ç”Ÿæˆè¦æ±‚ï¼š**
- å¦‚æœç”¨æˆ·è¦æ±‚ç”Ÿæˆæ–‡ä»¶ï¼Œå¿…é¡»ç¡®è®¤æ–‡ä»¶ç¡®å®å­˜åœ¨äºæ–‡ä»¶ç³»ç»Ÿä¸­
- ä»…ä»…å·¥å…·è¯´"å·²ä¿å­˜"æ˜¯ä¸å¤Ÿçš„ï¼Œå¿…é¡»æœ‰å®é™…çš„æ–‡ä»¶å­˜åœ¨
- å¦‚æœæœ‰æ–‡ä»¶ç”Ÿæˆè¦æ±‚ä½†æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä»»åŠ¡æœªå®Œæˆ
- æ£€æŸ¥æ–‡ä»¶è·¯å¾„å’Œæ–‡ä»¶åæ˜¯å¦æ­£ç¡®

**ğŸ¯ å†³ç­–è§„åˆ™ï¼š**
- åªæœ‰åœ¨æ‰€æœ‰ç”¨æˆ·è¦æ±‚éƒ½å·²ç»å®Œæˆæ—¶ï¼Œæ‰èƒ½æ ‡è®°ä¸ºå®Œæˆ
- å¦‚æœç”¨æˆ·è¦æ±‚ç”Ÿæˆæ–‡ä»¶ä½†æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå¿…é¡»ç»§ç»­æ¨ç†
- å¦‚æœè¿˜æœ‰ä»»ä½•æœªå®Œæˆçš„è¦æ±‚ï¼Œå¿…é¡»ç»§ç»­æ¨ç†å’Œä½¿ç”¨å·¥å…·

è¯·ç”¨JSONæ ¼å¼è¿”å›ä½ çš„å†³å®š:
{{
    "analysis": "è¯¦ç»†åˆ†æå½“å‰çŠ¶æ€å’Œæ¯ä¸ªç”¨æˆ·è¦æ±‚çš„å®Œæˆæƒ…å†µ",
    "is_complete": true/false,
    "final_answer": "æœ€ç»ˆç­”æ¡ˆçš„å®Œæ•´æè¿°(å¦‚æœå®Œæˆ)",
    "next_step": "ä¸‹ä¸€æ­¥å…·ä½“è®¡åˆ’(å¦‚æœéœ€è¦ç»§ç»­)"
}}

åªè¿”å›JSONæ ¼å¼å†…å®¹ã€‚"""

            print(f"ğŸ¤– å‘LLMå‘é€åˆ†æè¯·æ±‚:")
            print(f"â“ åˆ†æä»»åŠ¡: åŸºäºå·¥å…·æ‰§è¡Œç»“æœå’Œæ–‡ä»¶æ£€æŸ¥ï¼Œæ˜¯å¦èƒ½å¤Ÿå®Œæˆä»»åŠ¡")
            print(f"ğŸ“ æç¤ºè¯é•¿åº¦: {len(prompt)} å­—ç¬¦")

            # ğŸ†• æ˜¾ç¤ºæ–‡ä»¶æ£€æŸ¥ç»“æœ
            if file_check_result['has_file_requirement']:
                print(
                    f"ğŸ“ æ–‡ä»¶ç”Ÿæˆè¦æ±‚: {'âœ… å·²æ»¡è¶³' if file_check_result['requirement_satisfied'] else 'âŒ æœªæ»¡è¶³'}")
                if file_check_result['existing_files']:
                    print(
                        f"ğŸ“„ å·²å­˜åœ¨æ–‡ä»¶: {', '.join(file_check_result['existing_files'])}")
                if file_check_result['missing_files']:
                    print(
                        f"âŒ ç¼ºå¤±æ–‡ä»¶: {', '.join(file_check_result['missing_files'])}")

            response = await llm.ainvoke([HumanMessage(content=prompt)])

            # è§£æLLMå“åº”
            import json
            try:
                content = str(response.content).strip()
                if content.startswith('```json'):
                    content = content[7:]
                if content.endswith('```'):
                    content = content[:-3]

                decision = json.loads(content.strip())
                analysis = decision.get("analysis", "åˆ†æå·¥å…·æ‰§è¡Œç»“æœ")
                is_complete = decision.get("is_complete", False)
                final_answer = decision.get("final_answer", "")
                next_step = decision.get("next_step", "")

                print(f"ğŸ’­ LLMåˆ†æ: {analysis[:100]}...")
                print(f"ğŸ¯ æ˜¯å¦å®Œæˆ: {is_complete}")

                # ğŸ†• å¼ºåˆ¶æ–‡ä»¶æ£€æŸ¥ï¼šå¦‚æœæœ‰æ–‡ä»¶ç”Ÿæˆè¦æ±‚ä½†æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå¼ºåˆ¶ç»§ç»­æ¨ç†
                if file_check_result['has_file_requirement'] and not file_check_result['requirement_satisfied']:
                    print("âš ï¸ æ£€æµ‹åˆ°æ–‡ä»¶ç”Ÿæˆè¦æ±‚ä½†æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå¼ºåˆ¶ç»§ç»­æ¨ç†")
                    is_complete = False
                    if not next_step:
                        next_step = "å¿…é¡»ç¡®ä¿æ–‡ä»¶ç”Ÿæˆå·¥å…·çœŸæ­£åˆ›å»ºäº†æ–‡ä»¶"
                    analysis = f"æ–‡ä»¶ç”Ÿæˆè¦æ±‚æœªæ»¡è¶³ï¼š{file_check_result['missing_files']}"

                if is_complete and final_answer:
                    print("âœ… æ¨ç†å®Œæˆ")

                    # ğŸ†• æ·»åŠ ç»“æœè´¨é‡è¯„ä¼°å’Œä¼˜åŒ–å»ºè®®
                    quality_assessment = ""
                    if config.ENABLE_RESULT_QUALITY_ASSESSMENT:
                        quality_assessment = await evaluate_result_quality(
                            current_problem, final_answer, reasoning_chain, file_check_result, llm
                        )

                    ai_message = AIMessage(
                        content=f"âœ… æ¨ç†å®Œæˆï¼\n\nè§‚å¯Ÿ: {tool_output}\n\nåˆ†æ: {analysis}\n\næœ€ç»ˆç­”æ¡ˆ: {final_answer}\n\n{quality_assessment}"
                    )

                    return {
                        **state,
                        "messages": state["messages"] + [ai_message],
                        "final_answer": final_answer,
                        "observations": state["observations"] + [tool_output],
                        "reasoning_chain": reasoning_chain,
                        "next_action": "end"
                    }
                elif reached_max_iter:
                    print("â° è¾¾åˆ°æœ€å¤§è½®æ¬¡ï¼Œç»“æŸæ¨ç†")
                    final_answer = final_answer or f"åŸºäº{max_iter}è½®æ¨ç†çš„ç»“æœ: {analysis}"

                    # ğŸ†• æ·»åŠ ç»“æœè´¨é‡è¯„ä¼°å’Œä¼˜åŒ–å»ºè®®
                    quality_assessment = ""
                    if config.ENABLE_RESULT_QUALITY_ASSESSMENT:
                        quality_assessment = await evaluate_result_quality(
                            current_problem, final_answer, reasoning_chain, file_check_result, llm
                        )

                    ai_message = AIMessage(
                        content=f"â° è¾¾åˆ°æœ€å¤§æ¨ç†è½®æ¬¡ã€‚\n\nè§‚å¯Ÿ: {tool_output}\n\nåˆ†æ: {analysis}\n\næœ€ç»ˆç­”æ¡ˆ: {final_answer}\n\n{quality_assessment}"
                    )

                    return {
                        **state,
                        "messages": state["messages"] + [ai_message],
                        "final_answer": final_answer,
                        "observations": state["observations"] + [tool_output],
                        "reasoning_chain": reasoning_chain,
                        "next_action": "end"
                    }
                else:
                    print("ğŸ”„ ç»§ç»­æ¨ç†")
                    ai_message = AIMessage(
                        content=f"è§‚å¯Ÿ: {tool_output}\n\nåˆ†æ: {analysis}\n\nä¸‹ä¸€æ­¥: {next_step}\n\nç»§ç»­æ¨ç†..."
                    )

                    return {
                        **state,
                        "messages": state["messages"] + [ai_message],
                        "observations": state["observations"] + [tool_output],
                        "reasoning_chain": reasoning_chain,
                        "current_iteration": current_iter + 1,
                        "next_action": "continue_reasoning"
                    }

            except (json.JSONDecodeError, KeyError) as e:
                print(f"âŒ è§£æLLMå“åº”å¤±è´¥: {e}")
                ai_message = AIMessage(
                    content=f"è§‚å¯Ÿ: {tool_output}\n\nè§£æå“åº”å¤±è´¥: {e}\n\nç»§ç»­æ¨ç†..."
                )
                return {
                    **state,
                    "messages": state["messages"] + [ai_message],
                    "observations": state["observations"] + [tool_output],
                    "reasoning_chain": reasoning_chain,
                    "current_iteration": current_iter + 1,
                    "next_action": "continue_reasoning"
                }

        except Exception as e:
            print(f"âŒ LLMè°ƒç”¨å¤±è´¥: {e}")
            ai_message = AIMessage(
                content=f"è§‚å¯Ÿ: {tool_output}\n\nåˆ†æå¤±è´¥: {str(e)}\n\nç»§ç»­æ¨ç†..."
            )
            return {
                **state,
                "messages": state["messages"] + [ai_message],
                "observations": state["observations"] + [tool_output],
                "reasoning_chain": reasoning_chain,
                "current_iteration": current_iter + 1,
                "next_action": "continue_reasoning"
            }

    else:
        print("âš ï¸ æœªé…ç½®LLMï¼Œæ— æ³•åˆ¤æ–­æ˜¯å¦ç»§ç»­æ¨ç†")
        ai_message = AIMessage(
            content=f"è§‚å¯Ÿ: {tool_output}\n\næœªé…ç½®LLMï¼Œç»§ç»­æ¨ç†..."
        )
        return {
            **state,
            "messages": state["messages"] + [ai_message],
            "observations": state["observations"] + [tool_output],
            "reasoning_chain": reasoning_chain,
            "current_iteration": current_iter + 1,
            "next_action": "continue_reasoning"
        }
