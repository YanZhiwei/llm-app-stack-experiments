import os
import time
from typing import TYPE_CHECKING, Any, Dict, List

from config import config
from langchain_core.messages import AIMessage, HumanMessage

# æ–°å¢å¯¼å…¥
from langchain_openai import AzureChatOpenAI
from prompts import get_react_system_prompt
from tools import get_react_tools

# åŠ è½½ .env æ–‡ä»¶
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    # å¦‚æœæ²¡æœ‰å®‰è£… python-dotenvï¼Œç»§ç»­æ‰§è¡Œ
    pass

if TYPE_CHECKING:
    from state import ReActState

# Azure OpenAI é…ç½®
AZURE_OPENAI_DEPLOYMENT = os.getenv(
    "AZURE_OPENAI_CHAT_DEPLOYMENT_NAME", "gpt-4o-mini")
AZURE_OPENAI_API_VERSION = os.getenv(
    "AZURE_OPENAI_API_VERSION", "2024-12-01-preview")
AZURE_OPENAI_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT")
AZURE_OPENAI_API_KEY = os.getenv("AZURE_OPENAI_API_KEY")

# åˆ›å»ºLLMå¹¶ç»‘å®šå·¥å…·
llm = None
if AZURE_OPENAI_ENDPOINT and AZURE_OPENAI_API_KEY:
    llm = AzureChatOpenAI(
        azure_endpoint=AZURE_OPENAI_ENDPOINT,
        azure_deployment=AZURE_OPENAI_DEPLOYMENT,
        api_version=AZURE_OPENAI_API_VERSION,
        api_key=AZURE_OPENAI_API_KEY,  # type: ignore
        temperature=0.2,
    )
    # ç»‘å®šå·¥å…·åˆ°LLM - è¿™æ˜¯å®˜æ–¹æ¨èçš„æ–¹å¼
    tools = get_react_tools()
    llm_with_tools = llm.bind_tools(tools)


async def react_reasoning_agent(state: 'ReActState') -> 'ReActState':
    """æ ‡å‡†ReActæ¨ç†æ™ºèƒ½ä½“ - ä½¿ç”¨Thought/Action/Observationæ¨¡å¼"""

    print(f"\nğŸ§  [æ­¥éª¤{state.get('current_iteration', 0)}] å¼€å§‹æ¨ç†...")

    current_iter = state.get("current_iteration", 0)
    max_iter = state.get("max_iterations", config.DEFAULT_MAX_ITERATIONS)
    current_problem = state.get("current_problem", "")

    # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°
    if current_iter >= max_iter:
        print(f"âš ï¸ è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•° {max_iter}ï¼Œç»“æŸæ¨ç†")
        return {
            **state,
            "next_action": "end"
        }

    # å¦‚æœæ²¡æœ‰é…ç½®LLMï¼Œç›´æ¥ç»“æŸ
    if not llm_with_tools:
        print("âš ï¸ æœªé…ç½®LLMï¼Œæ— æ³•è¿›è¡Œæ¨ç†")
        return {
            **state,
            "messages": state["messages"] + [AIMessage(content="æœªé…ç½®LLMï¼Œæ— æ³•è¿›è¡Œæ¨ç†")],
            "next_action": "end"
        }

    try:
        # æ„å»ºReActæ ¼å¼çš„æç¤ºè¯
        messages = state["messages"]

        # ä½¿ç”¨æ ‡å‡†çš„ReActç³»ç»Ÿæç¤ºè¯
        system_prompt = get_react_system_prompt()

        # æ„å»ºå®Œæ•´çš„æ¶ˆæ¯åˆ—è¡¨
        full_messages = [HumanMessage(content=system_prompt)] + messages

        # ä½¿ç”¨ç»‘å®šå·¥å…·çš„LLMè¿›è¡Œæ¨ç†
        response = await llm_with_tools.ainvoke(full_messages)

        # æ›´æ–°çŠ¶æ€
        new_state = {
            **state,
            "messages": state["messages"] + [response],
            "current_iteration": current_iter + 1,
        }

        # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
        tool_calls = getattr(response, 'tool_calls', None)
        if tool_calls:
            print(f"ğŸ”§ æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨: {len(tool_calls)} ä¸ª")
            new_state["next_action"] = "tools"
        else:
            # æ£€æŸ¥æ˜¯å¦åŒ…å«æœ€ç»ˆç­”æ¡ˆ
            content = str(response.content).lower()
            if "final answer:" in content or "æœ€ç»ˆç­”æ¡ˆ:" in content:
                print("âœ… æ¨ç†å®Œæˆï¼Œæ‰¾åˆ°æœ€ç»ˆç­”æ¡ˆ")
                new_state["next_action"] = "end"
                # æå–æœ€ç»ˆç­”æ¡ˆ
                final_answer = extract_final_answer(str(response.content))
                if final_answer:
                    new_state["final_answer"] = final_answer
            else:
                print("ğŸ”„ ç»§ç»­æ¨ç†")
                new_state["next_action"] = "reasoning"

        return new_state

    except Exception as e:
        print(f"âŒ æ¨ç†å¤±è´¥: {e}")
        return {
            **state,
            "messages": state["messages"] + [AIMessage(content=f"æ¨ç†å¤±è´¥: {str(e)}")],
            "current_iteration": current_iter + 1,
            "next_action": "end"
        }


def extract_final_answer(content: str) -> str:
    """ä»å“åº”ä¸­æå–æœ€ç»ˆç­”æ¡ˆ"""
    content_lower = content.lower()

    # æŸ¥æ‰¾æœ€ç»ˆç­”æ¡ˆæ ‡è®°
    markers = [
        "final answer:",
        "æœ€ç»ˆç­”æ¡ˆ:",
        "answer:",
        "ç­”æ¡ˆ:",
        "result:",
        "ç»“æœ:"
    ]

    for marker in markers:
        if marker in content_lower:
            start_idx = content_lower.find(marker)
            answer_start = start_idx + len(marker)
            answer = content[answer_start:].strip()
            # æ¸…ç†ç­”æ¡ˆ
            if answer.startswith('\n'):
                answer = answer[1:]
            return answer

    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ ‡è®°ï¼Œè¿”å›æ•´ä¸ªå†…å®¹
    return content


async def react_executor_agent(state: 'ReActState') -> 'ReActState':
    """ReActæ‰§è¡Œæ™ºèƒ½ä½“ - å¤„ç†å·¥å…·æ‰§è¡Œç»“æœ"""

    print(f"\nğŸ”§ [æ­¥éª¤{state.get('current_iteration', 0)}] å¤„ç†å·¥å…·ç»“æœ...")

    # è·å–æœ€åä¸€æ¡æ¶ˆæ¯ï¼ˆå·¥å…·æ‰§è¡Œç»“æœï¼‰
    last_message = state["messages"][-1]
    tool_output = str(last_message.content)

    print(
        f"ğŸ“‹ å·¥å…·æ‰§è¡Œç»“æœ: {tool_output[:200]}{'...' if len(tool_output) > 200 else ''}")

    # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°
    current_iter = state.get("current_iteration", 0)
    max_iter = state.get("max_iterations", config.DEFAULT_MAX_ITERATIONS)

    if current_iter >= max_iter:
        print(f"âš ï¸ è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•° {max_iter}ï¼Œç»“æŸæ¨ç†")
        return {
            **state,
            "next_action": "end"
        }

    # ç»§ç»­æ¨ç†
    return {
        **state,
        "next_action": "reasoning"
    }
