import logging
import os
import sys
from typing import Any, Dict

from agent.configuration import Configuration
from agent.graph import generate_query
from agent.state import OverallState
from agent.tools_and_schemas import SearchQueryList
from langchain_core.messages import HumanMessage
from langchain_core.runnables import RunnableConfig

# æ·»åŠ  src ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.abspath(
    os.path.join(os.path.dirname(__file__), '../src')))


# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO,
                    format="%(asctime)s %(levelname)s %(message)s")
logger = logging.getLogger(__name__)


def check_env():
    """æ£€æŸ¥å¿…éœ€çš„ç¯å¢ƒå˜é‡ã€‚"""
    required_azure_vars = [
        "AZURE_OPENAI_API_KEY",
        "AZURE_OPENAI_ENDPOINT",
        "AZURE_OPENAI_API_VERSION",
        "AZURE_OPENAI_CHAT_DEPLOYMENT_NAME"
    ]
    missing = [var for var in required_azure_vars if not os.getenv(var)]
    if missing:
        print(f"[ç¯å¢ƒå˜é‡ç¼ºå¤±] ç¼ºå°‘: {', '.join(missing)}")
        return False
    return True


def test_generate_query():
    """æµ‹è¯• generate_query å‡½æ•°"""
    if not check_env():
        return

    # åˆ›å»ºæµ‹è¯•çŠ¶æ€
    test_state: OverallState = {
        "messages": [HumanMessage(content="äººå·¥æ™ºèƒ½åœ¨åŒ»ç–—è¯Šæ–­ä¸­çš„åº”ç”¨")],
        "search_query": [],
        "web_research_result": [],
        "sources_gathered": [],
        "initial_search_query_count": 3,
        "max_research_loops": 2,
        "research_loop_count": 0,
        "reasoning_model": "gpt-4o-mini",
    }

    # åˆ›å»ºé…ç½®
    config: RunnableConfig = {
        "configurable": {
            "azure_openai_api_key": os.getenv("AZURE_OPENAI_API_KEY"),
            "azure_openai_endpoint": os.getenv("AZURE_OPENAI_ENDPOINT"),
            "azure_openai_api_version": os.getenv("AZURE_OPENAI_API_VERSION"),
            "azure_openai_deployment": os.getenv("AZURE_OPENAI_CHAT_DEPLOYMENT_NAME"),
            "tavily_api_key": os.getenv("TAVILY_API_KEY"),
            "max_research_loops": 2,
            "reflection_model": "gpt-4o-mini",
            "answer_model": "gpt-4o-mini",
        }
    }

    try:
        logger.info("ğŸ§ª å¼€å§‹æµ‹è¯• generate_query å‡½æ•°...")
        logger.info(f"æµ‹è¯•é—®é¢˜: {test_state['messages'][0].content}")
        logger.info(f"åˆå§‹æŸ¥è¯¢æ•°é‡: {test_state['initial_search_query_count']}")

        # è°ƒç”¨ generate_query å‡½æ•°
        result = generate_query(test_state, config)

        # æ£€æŸ¥ç»“æœ
        logger.info("âœ… generate_query å‡½æ•°æ‰§è¡ŒæˆåŠŸ!")
        logger.info(f"ç”Ÿæˆçš„æŸ¥è¯¢: {result.get('search_query', [])}")

        # éªŒè¯ç»“æœæ ¼å¼
        if 'search_query' in result:
            queries = result['search_query']
            if isinstance(queries, list) and len(queries) > 0:
                logger.info(f"âœ… æˆåŠŸç”Ÿæˆ {len(queries)} ä¸ªæœç´¢æŸ¥è¯¢")
                for i, query in enumerate(queries, 1):
                    logger.info(f"  æŸ¥è¯¢ {i}: {query}")
            else:
                logger.warning("âš ï¸ ç”Ÿæˆçš„æŸ¥è¯¢æ ¼å¼ä¸æ­£ç¡®æˆ–ä¸ºç©º")
        else:
            logger.error("âŒ ç»“æœä¸­ç¼ºå°‘ 'search_query' å­—æ®µ")

    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        raise


def test_different_topics():
    """æµ‹è¯•ä¸åŒä¸»é¢˜çš„æŸ¥è¯¢ç”Ÿæˆ"""
    if not check_env():
        return

    test_topics = [
        "é‡å­è®¡ç®—çš„å‘å±•ç°çŠ¶",
        "å¯å†ç”Ÿèƒ½æºæŠ€æœ¯çš„æœ€æ–°è¿›å±•",
        "æœºå™¨å­¦ä¹ åœ¨é‡‘èé¢†åŸŸçš„åº”ç”¨",
        "åŒºå—é“¾æŠ€æœ¯çš„å•†ä¸šåº”ç”¨æ¡ˆä¾‹"
    ]

    config: RunnableConfig = {
        "configurable": {
            "azure_openai_api_key": os.getenv("AZURE_OPENAI_API_KEY"),
            "azure_openai_endpoint": os.getenv("AZURE_OPENAI_ENDPOINT"),
            "azure_openai_api_version": os.getenv("AZURE_OPENAI_API_VERSION"),
            "azure_openai_deployment": os.getenv("AZURE_OPENAI_CHAT_DEPLOYMENT_NAME"),
            "tavily_api_key": os.getenv("TAVILY_API_KEY"),
            "max_research_loops": 2,
            "reflection_model": "gpt-4o-mini",
            "answer_model": "gpt-4o-mini",
        }
    }

    for topic in test_topics:
        logger.info(f"\n{'='*50}")
        logger.info(f"æµ‹è¯•ä¸»é¢˜: {topic}")
        logger.info(f"{'='*50}")

        test_state: OverallState = {
            "messages": [HumanMessage(content=topic)],
            "search_query": [],
            "web_research_result": [],
            "sources_gathered": [],
            "initial_search_query_count": 2,  # å‡å°‘æŸ¥è¯¢æ•°é‡ä»¥åŠ å¿«æµ‹è¯•
            "max_research_loops": 2,
            "research_loop_count": 0,
            "reasoning_model": "gpt-4o-mini",
        }

        try:
            result = generate_query(test_state, config)
            queries = result.get('search_query', [])
            logger.info(f"âœ… ä¸ºä¸»é¢˜ '{topic}' ç”Ÿæˆäº† {len(queries)} ä¸ªæŸ¥è¯¢")
            for i, query in enumerate(queries, 1):
                logger.info(f"  æŸ¥è¯¢ {i}: {query}")
        except Exception as e:
            logger.error(f"âŒ ä¸»é¢˜ '{topic}' æµ‹è¯•å¤±è´¥: {e}")


if __name__ == "__main__":
    os.environ["LANGCHAIN_TRACING_V2"] = "false"
    os.environ["LANGCHAIN_ENDPOINT"] = ""
    print("ğŸ§ª generate_query å‡½æ•°æµ‹è¯•")
    print("=" * 50)

    # è¿è¡ŒåŸºæœ¬æµ‹è¯•
    test_generate_query()

    print("\n" + "=" * 50)
    print("ğŸ§ª å¤šä¸»é¢˜æµ‹è¯•")
    print("=" * 50)

    # è¿è¡Œå¤šä¸»é¢˜æµ‹è¯•
    test_different_topics()

    print("\nâœ… æ‰€æœ‰æµ‹è¯•å®Œæˆ!")


def test_multilingual_queries():
    """æµ‹è¯•å¤šè¯­è¨€æŸ¥è¯¢ç”Ÿæˆ"""
    if not check_env():
        return

    # å¤šè¯­è¨€æµ‹è¯•ç”¨ä¾‹
    multilingual_topics = [
        # ä¸­æ–‡æµ‹è¯•ç”¨ä¾‹
        "äººå·¥æ™ºèƒ½åœ¨åŒ»ç–—è¯Šæ–­ä¸­çš„åº”ç”¨",
        "é‡å­è®¡ç®—çš„å‘å±•ç°çŠ¶",
        "å¯å†ç”Ÿèƒ½æºæŠ€æœ¯çš„æœ€æ–°è¿›å±•",
        # è‹±æ–‡æµ‹è¯•ç”¨ä¾‹
        "Artificial intelligence applications in medical diagnosis",
        "Quantum computing development status",
        "Latest advances in renewable energy technology",
        # æ··åˆè¯­è¨€æµ‹è¯•ç”¨ä¾‹
        "AIåœ¨åŒ»ç–—è¯Šæ–­ä¸­çš„åº”ç”¨",
        "Quantum computing å‘å±•ç°çŠ¶",
        "Renewable energy æŠ€æœ¯è¿›å±•"
    ]

    config: RunnableConfig = {
        "configurable": {
            "azure_openai_api_key": os.getenv("AZURE_OPENAI_API_KEY"),
            "azure_openai_endpoint": os.getenv("AZURE_OPENAI_ENDPOINT"),
            "azure_openai_api_version": os.getenv("AZURE_OPENAI_API_VERSION"),
            "azure_openai_deployment": os.getenv("AZURE_OPENAI_CHAT_DEPLOYMENT_NAME"),
            "tavily_api_key": os.getenv("TAVILY_API_KEY"),
            "max_research_loops": 2,
            "reflection_model": "gpt-4o-mini",
            "answer_model": "gpt-4o-mini",
        }
    }

    logger.info(f"\n{'='*60}")
    logger.info("ğŸŒ å¤šè¯­è¨€æŸ¥è¯¢ç”Ÿæˆæµ‹è¯•")
    logger.info(f"{'='*60}")

    for topic in multilingual_topics:
        logger.info(f"\nğŸ“ æµ‹è¯•ä¸»é¢˜: {topic}")
        logger.info("-" * 40)

        test_state: OverallState = {
            "messages": [HumanMessage(content=topic)],
            "search_query": [],
            "web_research_result": [],
            "sources_gathered": [],
            "initial_search_query_count": 2,  # å‡å°‘æŸ¥è¯¢æ•°é‡ä»¥åŠ å¿«æµ‹è¯•
            "max_research_loops": 2,
            "research_loop_count": 0,
            "reasoning_model": "gpt-4o-mini",
        }

        try:
            result = generate_query(test_state, config)
            queries = result.get('search_query', [])
            logger.info(f"âœ… ç”Ÿæˆäº† {len(queries)} ä¸ªæŸ¥è¯¢")

            # åˆ†ææŸ¥è¯¢è¯­è¨€
            chinese_count = 0
            english_count = 0
            for query in queries:
                # ç®€å•çš„ä¸­æ–‡æ£€æµ‹ï¼ˆåŒ…å«ä¸­æ–‡å­—ç¬¦ï¼‰
                if any('\u4e00' <= char <= '\u9fff' for char in query):
                    chinese_count += 1
                else:
                    english_count += 1

            logger.info(
                f"ğŸ“Š è¯­è¨€åˆ†å¸ƒ: ä¸­æ–‡æŸ¥è¯¢ {chinese_count} ä¸ª, è‹±æ–‡æŸ¥è¯¢ {english_count} ä¸ª")

            for i, query in enumerate(queries, 1):
                logger.info(f"  æŸ¥è¯¢ {i}: {query}")

        except Exception as e:
            logger.error(f"âŒ ä¸»é¢˜ '{topic}' æµ‹è¯•å¤±è´¥: {e}")


if __name__ == "__main__":
    print("ğŸ§ª generate_query å‡½æ•°æµ‹è¯•")
    print("=" * 50)

    # è¿è¡ŒåŸºæœ¬æµ‹è¯•
    test_generate_query()

    print("\n" + "=" * 50)
    print("ğŸ§ª å¤šä¸»é¢˜æµ‹è¯•")
    print("=" * 50)

    # è¿è¡Œå¤šä¸»é¢˜æµ‹è¯•
    test_different_topics()

    # è¿è¡Œå¤šè¯­è¨€æµ‹è¯•
    test_multilingual_queries()

    print("\nâœ… æ‰€æœ‰æµ‹è¯•å®Œæˆ!")
